{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo On policy\n",
    "## Sources \n",
    "- Reinforcement Learning : An Introduction, by Richard Sutton and Andrew Barto\n",
    "\n",
    "Toujours basé sur le Blackjack, nous allons rechercher une politique optimum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de l'environnement Blackjack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Blackjack-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionnaire pour stocker les Q values (action-valeur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = defaultdict(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionnaire pour le total des retours G poour chaque couple s,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_return = defaultdict(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionnaire pour le cumul du nombre de passage pour tout les s,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = defaultdict(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définissons une politique epsilon-greedy\n",
    "Paramètres d'entrés   \n",
    "    - Q fonction (s,a)   \n",
    "    - L'état courant   \n",
    "    - epsilon   \n",
    " \n",
    "Paramètre de sortie    \n",
    "    - a action choisie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(state,Q,epsilon):\n",
    "  \n",
    "    if random.uniform(0,1) < epsilon:\n",
    "        return env.action_space.sample() # exploration\n",
    "    else:\n",
    "        max_q=-1\n",
    "        max_a=0\n",
    "        for a in range(env.action_space.n):\n",
    "            if (state,a) in Q:\n",
    "                if Q[(state,a)] > max_q:\n",
    "                    max_q=Q[(state,a)]\n",
    "                    max_a=a\n",
    "        return(max_a)\n",
    "        # return max(list(range(env.action_space.n)), key = lambda x: Q[(state,x)]) # exploitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=defaultdict(float)\n",
    "Z[ (1 , 0) ] = 10\n",
    "Z[ (1, 1) ] = 12\n",
    "assert epsilon_greedy_policy(1,Z,0) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Générateur d'épisode\n",
    "Entrée :\n",
    "- Q fonction\n",
    "- espilon pour notre politique aléatoire\n",
    "\n",
    "Sortie :\n",
    "- notre épisode sous la forma s,a ,s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_episode(Q,epsilon):\n",
    "    \n",
    "    episode = []\n",
    "    \n",
    "    state = env.reset()[0]\n",
    "    \n",
    "    for t in range(num_timesteps):\n",
    "        \n",
    "        # Sélection d'une action en fonction de notre politique\n",
    "        action = epsilon_greedy_policy(state,Q,espilon)\n",
    "        \n",
    "        # envoie de l'action à l'environnement pour retour (s_, r, done)\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        \n",
    "        # stockage dans la liste du triplet (état, action, récompense)\n",
    "        episode.append((state, action, reward))\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "        state = next_state\n",
    "\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Calcul de la politique optimale\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 500000\n",
    "espilon = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons initialiser une politique random au démarrage.      \n",
    "Selon le modèle GPI, Notre Q fonction va tendre vers les vrais valeurs et donc notre politique également.<br>\n",
    "Pour simplifier et parce que l'intéret est limité dans le cas du blackjack, nous ferons abstraction de gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "for i in range(num_iterations):\n",
    "    \n",
    "    # on génére un épisode\n",
    "    episode = generate_episode(Q,espilon)\n",
    "    \n",
    "    # on stocker les pairs s,a de l'épisode\n",
    "    all_state_action_pairs = [(s, a) for (s,a,r) in episode]\n",
    "    \n",
    "    # on stocke les récompense\n",
    "    rewards = [r for (s,a,r) in episode]\n",
    "\n",
    "    # Pour chaque t de l'épisode \n",
    "    for t, (state, action, reward) in enumerate(episode):\n",
    "\n",
    "        # First visit : on ne prend en compte que le premier passage s,a\n",
    "        if not (state, action) in all_state_action_pairs[0:t]:\n",
    "            \n",
    "            # Calcul de G avec y = 1\n",
    "            R = sum(rewards[t:])\n",
    "            \n",
    "            # Cumul G\n",
    "            total_return[(state,action)] = total_return[(state,action)] + R\n",
    "            \n",
    "            # Comptage du nombre de passage\n",
    "            N[(state, action)] += 1\n",
    "\n",
    "            # Calcul de Q value (s,a) par la moyenne des G cumulés sur N\n",
    "            Q[(state,action)] = total_return[(state, action)] / N[(state, action)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Regardons les résultats pour une situation données et suivant l'action choisie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.23262295081967213"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[((18,10,0),0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8879683675390698"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[((21,10,0),0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((19,1,1),1) in Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logique :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stockage du résultat dans un Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Q.items(),columns=['state_action pair','value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_action pair</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((21, 10, 1), 1)</td>\n",
       "      <td>-0.169492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((16, 10, 0), 0)</td>\n",
       "      <td>-0.564878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((16, 4, 0), 0)</td>\n",
       "      <td>-0.215698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((14, 9, 0), 0)</td>\n",
       "      <td>-0.549296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((21, 10, 1), 0)</td>\n",
       "      <td>0.920828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>((17, 8, 1), 1)</td>\n",
       "      <td>-0.092081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>((17, 8, 0), 0)</td>\n",
       "      <td>-0.384435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>((12, 10, 0), 0)</td>\n",
       "      <td>-0.585380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>((13, 10, 0), 1)</td>\n",
       "      <td>-0.579223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>((15, 7, 1), 0)</td>\n",
       "      <td>-0.455621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>((15, 5, 1), 1)</td>\n",
       "      <td>-0.059783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_action pair     value\n",
       "0   ((21, 10, 1), 1) -0.169492\n",
       "1   ((16, 10, 0), 0) -0.564878\n",
       "2    ((16, 4, 0), 0) -0.215698\n",
       "3    ((14, 9, 0), 0) -0.549296\n",
       "4   ((21, 10, 1), 0)  0.920828\n",
       "5    ((17, 8, 1), 1) -0.092081\n",
       "6    ((17, 8, 0), 0) -0.384435\n",
       "7   ((12, 10, 0), 0) -0.585380\n",
       "8   ((13, 10, 0), 1) -0.579223\n",
       "9    ((15, 7, 1), 0) -0.455621\n",
       "10   ((15, 5, 1), 1) -0.059783"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[((21,11,0),1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons un Q optimal ou proche.   \n",
    "Notre politique est basée sur une approche gloutonne de Q donc elle même optimale !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Exemple\n",
    "J'ai en main 19 points (sans as) et le croupier 5 points visibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_action pair</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>((19, 5, 0), 0)</td>\n",
       "      <td>0.434579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    state_action pair     value\n",
       "152   ((19, 5, 0), 0)  0.434579"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ df['state_action pair'] == ((19,5,False),0) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_action pair</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>((19, 5, 0), 1)</td>\n",
       "      <td>-0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    state_action pair  value\n",
       "154   ((19, 5, 0), 1)  -0.84"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ df['state_action pair'] == ((19,5,False),1) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ma politique va donc choisir un stand (0) car la valeur de fonction d'action-état est la plus haute !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
