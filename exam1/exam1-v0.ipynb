{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c425b9a1-862f-48fc-9472-32e44b023521",
   "metadata": {},
   "source": [
    "# Examen 1 : Cours A59 Apprentissage par renforcement\n",
    "<br>\n",
    "Nous allons lors de cet examen tester l'utilisation de Monte Carlo avec l'environnement CliffWalking.<br>\n",
    "\n",
    "L'objectif sera d'appliquer Monte Carlo first visit et de vérifier que l'algorithme est capable de résoudre le problème.<br>\n",
    "\n",
    "### Le plan est le suivant\n",
    "1) Découvrir l'environnement et répondre à quelques questions théoriques ( 9 pts)<br>\n",
    "2) Définir une politique (2pts)\n",
    "3) Lancer la simulation et en tirer les conclusions (10 pts)\n",
    "4) Ajouter epsilon à travers les itérations (4 pts)\n",
    "\n",
    "<br>\n",
    "Consignes:<br>\n",
    "\n",
    "Vous devrez compléter le code la ou est présente la mention __# votre code__ <br>\n",
    "Vous pouvez choisir d'implémenter différemment l'algortihme tant que vous utilisez Monte Carlo.<br>\n",
    "\n",
    "Vous devrez également répondre aux questions là ou vous trouverez la mention __# votre réponse__<br>\n",
    "\n",
    "Vous avez 3h00.<br>\n",
    "\n",
    "Le total est de 25 points.<br>\n",
    "\n",
    "__Merci de m'envoyer le notebook par MIO et en renommant le fichier avec votre nom__<br>\n",
    "\n",
    "C'est un travail personnel.<br>\n",
    "\n",
    "Les documents et TP sont permis.<br>\n",
    "<br>\n",
    "## Bonne chance !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605f9d60-4319-4211-b664-6ec80f131726",
   "metadata": {},
   "source": [
    "# Chargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911295f3-6a68-4087-bce2-812839943ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f111df-2c6a-415b-888a-7074a6134b53",
   "metadata": {},
   "source": [
    "# Environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4f569-a7c6-4977-a841-2003547e78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITERATION = 5000\n",
    "NUM_STEP=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5cccd8-eb52-4532-8a62-54db6245906a",
   "metadata": {},
   "source": [
    "## Cliffwalking\n",
    "\n",
    "Le détail de l'environnement est accessible ici : https://gymnasium.farama.org/environments/toy_text/cliff_walking/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbcc8df-f197-4e04-a00b-08fbe106b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CliffWalking-v0', render_mode=\"ansi\") \n",
    "\n",
    "# env_test sera utilisé plus tard pour visualier le résultat\n",
    "env_test = gym.make('CliffWalking-v0', render_mode=\"human\") # ,render_mode=\"ansi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1949a8-f8e2-44f2-ac5f-1eed14df5229",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737eb3e-8ba9-4c2c-8f45-767ddc7f2e16",
   "metadata": {},
   "source": [
    "### (1) Récupérer le nombre d'états possibles à l'aide la classe env et affecter cette valeur à la variable nombre_etat (1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd827f-d15a-4408-a42c-7404c79623ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre d'états\n",
    "\n",
    "nombre_etat = # votre code\n",
    "print(nombre_etat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d005c820-7451-4dc6-a3ba-ad27010ac748",
   "metadata": {},
   "source": [
    "### __Question : combien avons nous d'état ?__<br>\n",
    "__Votre réponse :__"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c3d7811-87de-4fa9-bce3-cc85a075f70e",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff000f-b622-45dd-ab2b-5e4093ced65b",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afc0507-1239-485f-88ff-275ef02b1908",
   "metadata": {},
   "source": [
    "### (2) Récupérer le nombre d'action possible à l'aide la classe env et affecter cette valeur à la variable nombre_action (1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d917c30-b95b-4153-ad37-620e7b6e0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre d'actions possibles\n",
    "\n",
    "nombre_action = # votre code\n",
    "print(nombre_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a843619-0340-4482-ba53-c4eacdf61800",
   "metadata": {},
   "source": [
    "### __Question : combien avons nous d'action ?__<br>\n",
    "__Votre réponse :__"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9327f4ce-9d7e-44f3-ab40-402d29356ddb",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47ee393-7273-4555-87a7-3d714a903777",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388b221-95b8-4b86-b659-62a64a2824a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La ligne suivante ne devrait pas générer d'erreur\n",
    "assert nombre_action+nombre_etat == 52"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b96ad1-ea9d-4134-93fb-95b94d8e5938",
   "metadata": {},
   "source": [
    "### (3) Question : est ce un environnement épisodique ou continu ? (1 pts)\n",
    "Votre réponse :"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d31e9c1-d0ef-4f67-8760-d722c1149e54",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f2c518-c132-4026-a968-3a85e0913b20",
   "metadata": {},
   "source": [
    "### (4) Question : est ce un environnement conforme aux critéres d'un processus de décision Markovien et pourquoi ? (3 pts)\n",
    "Votre réponse :"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8693b8a5-ee1e-41ff-96f3-cbfc49a92ab3",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ea3865-fb63-4df6-bb62-da93df21ea74",
   "metadata": {},
   "source": [
    "### (5) Question : Pouvez vous décrire en quelques lignes le principe de l'algorithme Monte Carlo ? (1.5 pts)\n",
    "Votre réponse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b25267-30ae-4637-935e-f1b48674a5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc01d022-6e4a-40ab-b695-8d4fb5be5eee",
   "metadata": {},
   "source": [
    "### (6) Question : Quelles sont les situations ou un algorithme Monte Carlo ne fonctionnera pas ? (1.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef47fa-ca4a-4316-aa74-9cd72615a4a7",
   "metadata": {},
   "source": [
    "Votre réponse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320c5af-b5bb-4b96-a13b-c561647b3ca1",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d7ee1-b14a-49b5-820e-052921b205e2",
   "metadata": {},
   "source": [
    "# (7) Fonctions utiles ( 2pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16572e-c0df-464e-8ad1-03e77ab9b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# définissons une politique e-greedy\n",
    "def policy(Q,epsilon,state):\n",
    "    # entrée : tableau de valeur Q (ou dict), epsilon,), état courant\n",
    "    # sortie : action choisie au hasard si nous tirons un nombre aléatoire inférieur à epsilon, sinon la meilleur action gloutonne\n",
    "\n",
    "    # votre code (2 pts) - 4 lignes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb833b-b275-4c27-806f-a28eafc41024",
   "metadata": {},
   "source": [
    "### ne devrait pas générer d'erreur mais cela peut varier avec votre version.\n",
    "Donc donner juste à titre indicatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec8b95-142c-4019-b618-de045c218ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) # valable si vous avez utilisé numpy pour générer les nombres aléatoires\n",
    "assert policy([0,1,5,2],0,0) == 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e6ae3e-8e4d-477c-8570-64a476987e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) # valable si vous avez utilisé numpy pour générer les nombres aléatoires\n",
    "env.action_space.seed(1)\n",
    "assert policy([0,1,5,2],1,0)==1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8858fb4-05f0-4af4-9816-2e459aa5417a",
   "metadata": {},
   "source": [
    "### Pas de modification nécessaire pour cette fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18041150-8a97-488b-815b-a2557722b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_episode(Q,epsilon,num_timesteps):\n",
    "    \n",
    "    episode = []\n",
    "    \n",
    "    state = env.reset()[0]\n",
    "\n",
    "    for t in range(num_timesteps):\n",
    "        \n",
    "        # Sélection d'une action en fonction de notre politique\n",
    "        action = policy(Q,epsilon,state)\n",
    "        \n",
    "        # envoie de l'action à l'environnement pour retour (s_, r, done)\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        \n",
    "        # stockage dans la liste du triplet (état, action, récompense)\n",
    "        episode.append((state, action, reward))\n",
    "        \n",
    "        if done or truncated:\n",
    "            break\n",
    "            \n",
    "        state = next_state\n",
    "\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95856eee-97a3-44d4-8d78-50c829c147c5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005cae4f-ff37-49d8-9fdc-2e2d1db4a9cd",
   "metadata": {},
   "source": [
    "# Lancons la simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434b520-06db-467e-a064-c71cd5858531",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Définissons nos 3 tableaux numpy avec 2 dimensions état/action:<br>\n",
    "__Q__ : fonction d'action valeur donc indexé sur les états et les actions par état. Attention à initialiser avec 0.0<br>\n",
    "__total_return__ :  cumul par couple état/action des récompenses<br>\n",
    "__N__ : comptage du nombre de passage par couple état/action choisie<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3986afda-691f-482f-8417-c8a2bfab1acb",
   "metadata": {},
   "source": [
    "### début repère 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc7a762-de7d-41f4-92c7-10cca1a76a15",
   "metadata": {},
   "source": [
    "### (8) Créer et initialiser les tableaux (1 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc635f54-dfff-4c4f-9880-7e44774169e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "Q = \n",
    "total_return = \n",
    "N = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e8702-934b-4559-bfe0-71e2d521fdd2",
   "metadata": {},
   "source": [
    "### (9) écrivez le code manquant Monte Carlo __First visit__  (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50212617-3dfa-4637-848b-d6658764e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition FIXES du test\n",
    "np.random.seed(1)\n",
    "num_iterations=NUM_ITERATION\n",
    "num_step=NUM_STEP\n",
    "epsilon=0.20\n",
    "gamma=1 # doit faciliter le calcul de G\n",
    "\n",
    "# expérimentation\n",
    "historique_duree_partie = []\n",
    "historique_recompense = []\n",
    "for i in range(num_iterations):\n",
    "    \n",
    "    # on génére un épisode\n",
    "    episode = generate_episode(Q,epsilon,num_step)\n",
    "    \n",
    "    # on stocker les pairs s,a de l'épisode\n",
    "    all_state_action_pairs = [(s, a) for (s,a,r) in episode]\n",
    "    \n",
    "    # on stocke les récompense\n",
    "    rewards = [r for (s,a,r) in episode]\n",
    "\n",
    "    historique_duree_partie.append(len(episode))\n",
    "    historique_recompense.append(np.sum(rewards))\n",
    "\n",
    "    # en appliquant l'algorithme de Monte Carlo première visite, metter à jour total_return, N et par calcul Q\n",
    "    # votre code (environ 6 lignes) ( 5pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f735342-2075-44d1-8f73-c55ec380574a",
   "metadata": {},
   "source": [
    "---\n",
    "### Affichons l'évolution de la durée des épisodes au fil de l'expérimentation et l'historique des récompenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd0b9a-52bf-40e9-9108-3b8a8d402fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f ,(ax1,ax2) = plt.subplots(2,1,sharex=True)\n",
    "\n",
    "ax1.set_title(\"Durée des épisodes\")\n",
    "ax1.plot(historique_duree_partie)\n",
    "\n",
    "ax2.set_title(\"Récompense\")\n",
    "ax2.plot(historique_recompense)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da792a7-5735-4c51-8a3e-fa7db810dc5d",
   "metadata": {},
   "source": [
    "### fin repère 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807a497c-1c8a-4e1f-83f0-93e97628dca5",
   "metadata": {},
   "source": [
    "## Vous devriez observer des courbes proches de celles ci dessous\n",
    "\n",
    "![courbes](static/courbes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a0af83-36f0-4fb8-b685-1e3f6b35b800",
   "metadata": {},
   "source": [
    "### (10) Question : quelle est l'action recommandée par notre politique en position 36 ? Est ce correct ? (1 pt)\n",
    "Votre réponse :"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbe5b461-6e99-4de2-b735-decf56ff2789",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4caf00-f7b0-4d14-9736-56f537001cef",
   "metadata": {},
   "source": [
    "### (11) Question : quelle est l'action recommandée par notre politique en position 35 ? Est ce correct ? (1 pt)\n",
    "Votre réponse :"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d407da33-98d5-4349-be29-d98a84ef9b91",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd7bc0-7333-4827-9770-e4cd8c3c5b07",
   "metadata": {},
   "source": [
    "### Affichons une simulation d'un épisode.\n",
    "Note : si vous avez des difficultés à la version graphique, vous pouvez changer le mode render_mode=\"ansi\" pour env_test et ajouter un print(env.render()) dans la boucle\n",
    "\n",
    "#### Note il pourrait arriver que l'agent se bloque dans une colonne de la case gauche. Cela ne veut pas dire que votre algorithme n'a pas fonctionné mais nécessite plus d'entrainement.\n",
    "\n",
    "__Solution : refaite un entrainement à partir de la section début repère 1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1883c21e-c2cd-4e7d-8080-50c6bfccb754",
   "metadata": {},
   "outputs": [],
   "source": [
    "state=env_test.reset()[0]\n",
    "done=False\n",
    "while not done:\n",
    "    action=policy(Q,0,state)\n",
    "    state,_,done,truncated,_ = env_test.step(action)\n",
    "    # print(env.render())\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ec106-a41d-4c09-9a8b-3ac5be169acd",
   "metadata": {},
   "source": [
    "### (12) Question : Le petit homme prend il le chemin le plus court et pourquoi ? (2.0 pt)\n",
    "Votre réponse :"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38366fe0-a376-4f2e-9d1a-7a7bf4c701a4",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fadc073-d46d-4204-a7ff-a411253fd6eb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af486954-4d23-419d-9ae3-0dc46bc1ca5a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a9f3d-9113-4e13-a8c3-85630b8d038c",
   "metadata": {},
   "source": [
    "## Copier le code compris entre les balises **début repère 1** et **fin repère 1** ci dessous.\n",
    "## Notre approche e-greedy n'est pas complétement satisfaisante.\n",
    "## Nous allons faire une décroissance d'espilon progressive.\n",
    "### (13) Modifier le code pour faire évoluer epsilon de 0.90 à 0.05 selon un nombre d'éspisode que je vous laisse apprécier et relancer l'expérimentation. (3 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb1fc03-8793-4801-be2d-54c76d2c73f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f28107-4233-409c-99bd-9c7c584537ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54be24c-52c5-429f-a2ce-39dffc63dbde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7105e2c-926c-4ec8-9653-85dcc942b290",
   "metadata": {},
   "source": [
    "Vous devriez obtenir des courbes prochent de celles ci (peut varier)\n",
    "\n",
    "![courbes](static/courbes_decay.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f486f8a6-0ab1-4b8d-a8aa-eb8d24e3d730",
   "metadata": {},
   "source": [
    "### (14) Question : pourquoi la partie gauche des courbes est elle plus épaisse qu'avec une valeur d'epsilon fixe ? (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0e7b0-b022-4dbb-9393-bf1cdb009f4c",
   "metadata": {},
   "source": [
    "votre résponse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd9dc1e-2054-4b37-b13c-77f116db6c99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b037d1-459e-45b5-a9f6-373686d471f9",
   "metadata": {},
   "source": [
    "# Ne pas oublier de m'envoyer le notebook par MIO !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
