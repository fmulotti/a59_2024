{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b786604b-3a1e-453b-b855-1929baef741b",
   "metadata": {},
   "source": [
    "# DQN avec réseau convolutionnel\n",
    "(c) Fabrice Mulotti + nombreuses sources sur internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a9e0a-7ae2-4209-9249-4ca93248fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b779e13-d03f-4584-9b18-33cab03b4a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input,Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import gymnasium as gym\n",
    "import timeit\n",
    "import ale_py\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6c020-b944-47ce-81c9-deaca20186e4",
   "metadata": {},
   "source": [
    "## Exemple si vous utilisez prometheus / grafana pour le suivi\n",
    "from prometheus_client import start_http_server, Gauge<br>\n",
    "collectReturn = Gauge(os.uname()[1] + \"_dqn_atari_return\",\"DQn Atari\")<br>\n",
    "\n",
    "start_http_server(9222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f05cc6-5082-41bd-8e58-e4b4f2563c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check version\n",
    "print(tf.__version__)\n",
    "print(\"Version numpy : \",np.__version__)\n",
    "print(f\"GPU?{tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91022521-6d6b-45f7-ab96-ac71e30ed31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environnement --------------------------------------\n",
    "ENV=\"ALE/Pong-v5\"\n",
    "env=gym.make(ENV,render_mode= \"rgb_array\", obs_type = \"grayscale\")\n",
    "action_size=env.action_space.n\n",
    "\n",
    "# ## Dimensions cible pour diminuer le temps de traitement\n",
    "state_size = (88, 80, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d25fefc-a4f0-4769-b340-4b352d41b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecrivez une fonction qui prend en entrée l'image du jeux - sous format greyscale\n",
    "# La fonction doit réduire l'image à 88,80 puis normaliser les pixels (exemple entre 0 et 1 moyenne 0.5)\n",
    "# La fonction doit ensuite retourner un numpy format 88,80,1\n",
    "\n",
    "# Exemple de fonction utilise from skimage.transform import resize\n",
    "# Mais il en existe d'autre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f8a3ba-439a-4626-8ab2-cb893b93d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réduction de la taille des images\n",
    "def getState(state):\n",
    "    state=resize(state,(88,80),anti_aliasing=False)\n",
    "    # state = state/256 # à utiliser suivant l'outil de réduction d'image utilisé\n",
    "    return np.expand_dims(state,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f0b31-ae52-438a-bf90-084d48aa3961",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=env.reset()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36af3f-5cc8-4974-a4c5-4310f7b178b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bb9032-c71b-4dcf-9e1b-0982931cd6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d6c25-27e8-42eb-ba32-07bccaf45ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"min {s.min()}, max {s.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d06ee-2c6f-41c5-8a3b-7c110003075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46fc37-6882-450c-a76a-ef692b06f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_reduce=getState(s)\n",
    "print(s_reduce.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a45844a8-22c1-47c1-acb4-ade4eab45605",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "# Vérifions que tout est beau\n",
    "assert s_reduce.shape == (88,80,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a1a31-7db7-49a9-a42a-fc1bb46c99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_reduce.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44100d9-7e90-4566-b9e2-cdc2bb5826f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"min {s_reduce.min()}, max {s_reduce.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02798242-5411-4aa9-92be-f26382719196",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(getState(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445cb59a-ef45-472c-96ae-ea83348f4850",
   "metadata": {},
   "source": [
    "# Classe DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced3ce55-b50a-42b9-b0fb-201e96202c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Notre classe DQN\n",
    "class DQN:\n",
    "    def __init__(self, state_size, action_size, gamma = 0.99, update_rate=2000,lr=2.5e-4):\n",
    "        \n",
    "        #dimension état\n",
    "        self.state_size = state_size\n",
    "        \n",
    "        #nombre action\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        # déclaration + taille replay buffer\n",
    "        self.replay_buffer = deque(maxlen=100000)\n",
    "        \n",
    "        # dévaluation\n",
    "        self.gamma = gamma\n",
    "                \n",
    "        # fréquence de copie des poids main-> target\n",
    "        self.update_rate = update_rate\n",
    "\n",
    "        # learning rate\n",
    "        self.lr=lr\n",
    "        \n",
    "        # réseau main\n",
    "        self.main_network = self.build_network()\n",
    "        \n",
    "        # réseau target\n",
    "        self.target_network = self.build_network()\n",
    "        \n",
    "        #initialisation poids identiques\n",
    "        self.target_network.set_weights(self.main_network.get_weights())\n",
    "        \n",
    "\n",
    "    # construction réseau \n",
    "    def build_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=self.state_size))\n",
    "\n",
    "        # ajoutez 2 ou 3 couches cachées de  type convolutionnel\n",
    "        #.      L'activation sera de type relu\n",
    "        # Mettre à \"plat\" ensuite les couches\n",
    "        # ajouter une couche dense 512 neurones/relu\n",
    "        # ajouter une couche de sortie avec un neurone par action possible, type linear\n",
    "\n",
    "        \n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.lr),jit_compile=True)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def transformState(self,state):\n",
    "        return np.expand_dims(state,axis=0)\n",
    "    \n",
    "    # enregistrement SARS dans replay buffer\n",
    "    def store_transition(self, state, action, reward, next_state, done):\n",
    "        self.replay_buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    # choix action epsilon greedy\n",
    "    def epsilon_greedy(self, state,epsilon):\n",
    "        \n",
    "        if random.uniform(0,1) < epsilon:\n",
    "            return np.random.randint(self.action_size)\n",
    "        \n",
    "        # print(state.shape,self.transformState(state).shape)\n",
    "        Q_values = self.main_network.predict_on_batch(self.transformState(state)) \n",
    "        \n",
    "        return np.argmax(Q_values[0])\n",
    "\n",
    "    @tf.function\n",
    "    def _train(self,states,targets):\n",
    "        self.main_network.fit(states, targets, epochs=1, verbose=0)\n",
    "                         \n",
    "    def train_model(self,batch_size):\n",
    " \n",
    "        # sélection d'un échantillon\n",
    "        minibatch = random.sample(self.replay_buffer,batch_size)\n",
    "        states, actions, rewards, next_states, dones = map(np.array, zip(*minibatch))\n",
    "\n",
    "        states=states.squeeze()\n",
    "        next_states=next_states.squeeze()\n",
    "        \n",
    "        # On récupere les Q values des états rencontrés\n",
    "        Q_values = self.main_network.predict(states,verbose = 0)\n",
    "        \n",
    "        Updates = rewards + self.gamma * np.amax(self.target_network.predict(next_states,verbose=0),axis=1) * (1-dones)\n",
    "        \n",
    "        Q_values[ np.arange(len(Updates)),actions] = Updates\n",
    "        \n",
    "        self._train(states, Q_values)       \n",
    "\n",
    "    # copie des poids main -> target\n",
    "    def update_target_network(self):\n",
    "        self.target_network.set_weights(self.main_network.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e21a21-4f95-4306-9fad-67a611c06526",
   "metadata": {},
   "source": [
    "# Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12904dd2-6887-4f49-b865-d1fde29cf11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Training the network\n",
    "num_episodes = 20000\n",
    "num_timesteps = 5000 # max pour un  épisode\n",
    "batch_size = 16 # nombre d enregistrement du replay buffer utilisé pour entrainer le modèle\n",
    "\n",
    "# Si problème à ce stade, regardez si vous avez des processus qui consomme votre GPU (nvidia-smi)\n",
    "dqn = DQN((88,80,1), action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd07b7ce-8ebe-4002-a30e-3fa152f1c881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weightsFile = \"dqn_atari_poseidon.weights.h5\"\n",
    "\n",
    "# Decommentez si vous repartez d'un entrainement\n",
    "#print(\"Load weights\")\n",
    "#dqn.main_network.load_weights(weightsFile)\n",
    "#dqn.target_network.load_weights(weightsFile)\n",
    "\n",
    "# ## C'est parti \n",
    "done = False\n",
    "time_step = 0\n",
    "\n",
    "# decay epsilon pour egreedy\n",
    "epsilon_max = 1.0\n",
    "epsilon_min=0.10\n",
    "epsilon_decay=1000\n",
    "epsilon = epsilon_max\n",
    "\n",
    "returnHistory=[]\n",
    "meanReturnShift=-1\n",
    "startTime=time.time()\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    Return = 0\n",
    "    \n",
    "    # on récupère notre premier état S\n",
    "    # initialisez l'environnement, récupérez et transformez l'état\n",
    "    # 2 lignes\n",
    "\n",
    "    for t in range(num_timesteps):        \n",
    "        \n",
    "        time_step += 1\n",
    "        \n",
    "        # suivant notre fréquence copie des poids main-> target\n",
    "        if time_step % dqn.update_rate == 0:\n",
    "            dqn.update_target_network()\n",
    "        \n",
    "        # sélection action et exécution\n",
    "        # sélectionnez une action avec egreedy\n",
    "        # Jouez l'action et récupérer le retour de l'environnement\n",
    "        # Transformez l'état\n",
    "        # 3 lignes\n",
    "        \n",
    "        # option parfois conseille pour les entrainements suivant le systeme de recompense\n",
    "        # if done:\n",
    "        #    reward += -100\n",
    "\n",
    "        # enregistrement SARS dans replay buffer\n",
    "        dqn.store_transition(state, action, reward, next_state, done)\n",
    "        \n",
    "        # transition\n",
    "        state = next_state\n",
    "        \n",
    "        Return += reward\n",
    "        \n",
    "        if i% 100 == 0:\n",
    "            # env.render()\n",
    "            dqn.main_network.save_weights(weightsFile)\n",
    "\n",
    "        # entrainement\n",
    "        if len(dqn.replay_buffer) > batch_size:\n",
    "            dqn.train_model(batch_size)\n",
    "            \n",
    "        if done:\n",
    "            r=max((epsilon_decay - i)/epsilon_decay,0)\n",
    "            epsilon=(epsilon_max-epsilon_min)*r + epsilon_min\n",
    "            break\n",
    "            \n",
    "\n",
    "    # stock le Gain\n",
    "    returnHistory.append(Return)\n",
    "    \n",
    "    # collecte avec prometheus grafana\n",
    "    # collectReturn.set(Return) \n",
    "    \n",
    "    # calcul la moyenne glissante des récompenses\n",
    "    if len(returnHistory)>100:\n",
    "        meanReturnShift=np.round(sum(returnHistory[-100:])/100,0)\n",
    "    \n",
    "    print(f\"Episode: {i}, Return={Return},in {t} moves,{time_step} total moves. \\\n",
    "    mean return={meanReturnShift}, \\\n",
    "    epsilon {np.round(epsilon,2)}. deque usage {np.round(len(dqn.replay_buffer)/1000,2)}% \\\n",
    "    , time/episode {np.round((time.time()-startTime)/(i+1))} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a48942-3669-4b2f-8cc4-8038a2947025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778d798-47d7-4744-952c-be850c489a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
