{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de6f9cc4-46f6-47c8-8680-e3982fee4474",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DQN \n",
    "## Cartpole\n",
    "\n",
    "Fabrice Mulotti\n",
    "\n",
    "v2.1 -résolu en 500 cycles environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ddb3de-19da-4e49-a52e-2e7bd972f225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 15:02:58.555347: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-24 15:02:58.555687: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-24 15:02:58.557591: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-24 15:02:58.563009: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-24 15:02:58.571677: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-24 15:02:58.574290: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-24 15:02:58.581040: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-24 15:02:59.012767: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten , Input\n",
    "from keras.optimizers import Adam # si vous utilisz un mac M1/M2, sinon le legacy n'est pas nécessaire\n",
    "# from keras.optimizers import  Adam # si vous utilisz un mac, sinon le legacy n'est pas nécessaire\n",
    "\n",
    "# from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a7419a-fda1-4a7d-9bdb-03f193d88644",
   "metadata": {},
   "source": [
    "---\n",
    "## Définition de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97eede1d-4dd6-498f-b2c3-2ea15a288abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d actions : 2, Dimension de l env : 4\n"
     ]
    }
   ],
   "source": [
    "ENV_NAME = 'CartPole-v1'\n",
    "\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(100)\n",
    "env.reset(seed=100)\n",
    "nb_actions = env.action_space.n # Nombre d'action\n",
    "nb_obs = env.observation_space.shape[0] # nombre de paramètre pour décrire l'environnement\n",
    "print(f\"Nombre d actions : {nb_actions}, Dimension de l env : {nb_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc064f29-c6b1-456b-86eb-4d43106ae655",
   "metadata": {},
   "source": [
    "# Remarques sur l'environnement\n",
    "\n",
    "2 actions possibles :<br>\n",
    "    poussée vers la gauche<br>\n",
    "    poussée vers la droite<br>\n",
    "    \n",
    "Observation :<br>\n",
    "    Valeurs **continues** !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3134929-d0c4-4539-a04c-1880f5092a5d",
   "metadata": {},
   "source": [
    "## Fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27478b51-e6ad-472d-b60a-cdb2b9313de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe pour notre algorithme DQN\n",
    "class DQN:\n",
    "    def __init__(self, obs_size, action_size, gamma, learning_rate):\n",
    "        # Objet : initialisation de la classe\n",
    "        # Paramètres en entrée\n",
    "        #     Nombre de paramètre pour décrire l'état\n",
    "        #     Nombre d'actions\n",
    "        #.    Paramètre gamma : dépréciation futur\n",
    "        #     learning rate\n",
    "        \n",
    "        # dimension des états\n",
    "        self.obs_size = obs_size\n",
    "        \n",
    "        # nombre d'actions\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        # gamma : dépréciation du futur\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # autres paramètres\n",
    "        self.update_freq = 100 # fréquence de copie des poids (1000)\n",
    "        \n",
    "        # autres structures\n",
    "        self.replay_buffer = deque(maxlen=100000) # enregistrements des résultats\n",
    "        \n",
    "        # Modèle de réseaux de neurones\n",
    "        self.main_network = self.build_model(16,8)\n",
    "        self.target_network = self.build_model(16,8)\n",
    "        # recopie des poids pour avoir des réseaux à l'identique\n",
    "        self.target_network.set_weights(self.main_network.get_weights())\n",
    "        \n",
    "        self.debug = 0\n",
    "        \n",
    "    def build_model(self,layer1,layer2):\n",
    "        # input : size of the 2 layers\n",
    "        # output : model of neural network\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(self.obs_size,)))\n",
    "        model.add(Dense(layer1,activation='relu'))\n",
    "        model.add(Dense(layer2,activation='relu'))\n",
    "        model.add(Dense(self.action_size))\n",
    "        model.add(Activation('linear'))\n",
    "        model.compile(loss='mse',optimizer=Adam(learning_rate=self.learning_rate),jit_compile=True)\n",
    "        return model\n",
    "\n",
    "    def store_transition(self,state,action,reward,next_state,done):\n",
    "        # input : \n",
    "        # output : nothing\n",
    "        self.replay_buffer.append((state,action,reward,next_state,done))\n",
    "      \n",
    "    # @tf.function\n",
    "    def mainPredict(self,state):\n",
    "        actions = self.main_network.predict(state,verbose=0)\n",
    "        return actions\n",
    "        \n",
    "    def policy(self, state, epsilon):\n",
    "        # Policy : return action regarding the state according to the policy\n",
    "        r = np.random.uniform()\n",
    "        if r < epsilon:\n",
    "            action = np.random.randint(self.action_size)\n",
    "        else:\n",
    "            actions=self.mainPredict(state)\n",
    "            action = np.argmax(actions[0])\n",
    " \n",
    "        return action\n",
    "    \n",
    "    # sous fonction entrainement graph\n",
    "    @tf.function\n",
    "    def _train_step(self, states, Q_values):    \n",
    "            self.main_network.fit(states,Q_values,epochs=1,verbose=0)\n",
    "            \n",
    "    def debugP(self,message):\n",
    "        if self.debug:\n",
    "            print(message)\n",
    "            \n",
    "    def train_model(self,batch_size):\n",
    "        self.debug=0\n",
    "        # sélection d'un échantillon\n",
    "        minibatch = random.sample(self.replay_buffer,batch_size)\n",
    "        states, actions, rewards, next_states, dones = map(np.array, zip(*minibatch))\n",
    "\n",
    "        states=states.squeeze()\n",
    "        next_states=next_states.squeeze()\n",
    "        \n",
    "        self.debugP(f\"states shape {states.shape}\")\n",
    "\n",
    "        # On récupere les Q values des états rencontrés\n",
    "        Q_values = self.main_network.predict(states,verbose = 0)\n",
    "        self.debugP(f\"Q_values shape {Q_values.shape}\")\n",
    "        \n",
    "        Updates = rewards + self.gamma * np.amax(self.target_network.predict(next_states,verbose=0),axis=1) * (1-dones)\n",
    "        self.debugP(f\"Update {Updates.shape}\")\n",
    "        \n",
    "        Q_values[ np.arange(len(Updates)),actions] = Updates\n",
    "        \n",
    "        self._train_step(states, Q_values)\n",
    "        \n",
    "    \n",
    "    def update_weights(self):\n",
    "        self.target_network.set_weights(self.main_network.get_weights())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f92ff9dc-3ba9-4ee4-80eb-37f999105bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des données pour compatabilité avec l'alimentation du réseau de neurones (1,s)`\n",
    "def trans_state(s):\n",
    "    return  np.reshape(s, [1, nb_obs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40544b87-cea1-49c8-b7aa-caecff66e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 1000\n",
    "batch_size = 16\n",
    "gamma=0.99 \n",
    "\n",
    "# variation du epsilon de notre politique e-greedy\n",
    "epsilon_max=1.00\n",
    "epsilon_min=0.10\n",
    "epsilon_decay=0.992 \n",
    "\n",
    "learning_rate=0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a6730c-1bc9-4f15-932f-1a6da59271fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQN(env.observation_space.shape[0],env.action_space.n,gamma,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42bdfe4d-af45-451f-9d3b-7722f880429a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager ? True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Eager ? {tf.executing_eagerly()}\")\n",
    "tf.config.optimizer.set_jit(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f7a5c03-286a-47d9-8361-3136ca70777f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  0 ,Return 18.0 , epsilon  1.0 , end= False\n",
      "Episode:  1 ,Return 16.0 , epsilon  0.99 , end= False\n",
      "Episode:  2 ,Return 28.0 , epsilon  0.98 , end= False\n",
      "Episode:  3 ,Return 18.0 , epsilon  0.98 , end= False\n",
      "Episode:  4 ,Return 19.0 , epsilon  0.97 , end= False\n",
      "Episode:  5 ,Return 16.0 , epsilon  0.96 , end= False\n",
      "Episode:  6 ,Return 42.0 , epsilon  0.95 , end= False\n",
      "Episode:  7 ,Return 10.0 , epsilon  0.95 , end= False\n",
      "Episode:  8 ,Return 13.0 , epsilon  0.94 , end= False\n",
      "Episode:  9 ,Return 23.0 , epsilon  0.93 , end= False\n",
      "Episode:  10 ,Return 14.0 , epsilon  0.92 , end= False\n",
      "Episode:  11 ,Return 33.0 , epsilon  0.92 , end= False\n",
      "Episode:  12 ,Return 56.0 , epsilon  0.91 , end= False\n",
      "Episode:  13 ,Return 11.0 , epsilon  0.9 , end= False\n",
      "Episode:  14 ,Return 28.0 , epsilon  0.89 , end= False\n",
      "Episode:  15 ,Return 21.0 , epsilon  0.89 , end= False\n",
      "Episode:  16 ,Return 18.0 , epsilon  0.88 , end= False\n",
      "Episode:  17 ,Return 19.0 , epsilon  0.87 , end= False\n",
      "Episode:  18 ,Return 18.0 , epsilon  0.87 , end= False\n",
      "Episode:  19 ,Return 15.0 , epsilon  0.86 , end= False\n",
      "Episode:  20 ,Return 33.0 , epsilon  0.85 , end= False\n",
      "Episode:  21 ,Return 24.0 , epsilon  0.84 , end= False\n",
      "Episode:  22 ,Return 25.0 , epsilon  0.84 , end= False\n",
      "Episode:  23 ,Return 40.0 , epsilon  0.83 , end= False\n",
      "Episode:  24 ,Return 22.0 , epsilon  0.82 , end= False\n",
      "Episode:  25 ,Return 30.0 , epsilon  0.82 , end= False\n",
      "Episode:  26 ,Return 13.0 , epsilon  0.81 , end= False\n",
      "Episode:  27 ,Return 39.0 , epsilon  0.81 , end= False\n",
      "Episode:  28 ,Return 26.0 , epsilon  0.8 , end= False\n",
      "Episode:  29 ,Return 45.0 , epsilon  0.79 , end= False\n",
      "Episode:  30 ,Return 41.0 , epsilon  0.79 , end= False\n",
      "Episode:  31 ,Return 18.0 , epsilon  0.78 , end= False\n",
      "Episode:  32 ,Return 27.0 , epsilon  0.77 , end= False\n",
      "Episode:  33 ,Return 17.0 , epsilon  0.77 , end= False\n",
      "Episode:  34 ,Return 15.0 , epsilon  0.76 , end= False\n",
      "Episode:  35 ,Return 44.0 , epsilon  0.75 , end= False\n",
      "Episode:  36 ,Return 27.0 , epsilon  0.75 , end= False\n",
      "Episode:  37 ,Return 62.0 , epsilon  0.74 , end= False\n",
      "Episode:  38 ,Return 52.0 , epsilon  0.74 , end= False\n",
      "Episode:  39 ,Return 51.0 , epsilon  0.73 , end= False\n",
      "Episode:  40 ,Return 34.0 , epsilon  0.73 , end= False\n",
      "Episode:  41 ,Return 55.0 , epsilon  0.72 , end= False\n",
      "Episode:  42 ,Return 16.0 , epsilon  0.71 , end= False\n",
      "Episode:  43 ,Return 9.0 , epsilon  0.71 , end= False\n",
      "Episode:  44 ,Return 12.0 , epsilon  0.7 , end= False\n",
      "Episode:  45 ,Return 81.0 , epsilon  0.7 , end= False\n",
      "Episode:  46 ,Return 106.0 , epsilon  0.69 , end= False\n",
      "Episode:  47 ,Return 31.0 , epsilon  0.69 , end= False\n",
      "Episode:  48 ,Return 83.0 , epsilon  0.68 , end= False\n",
      "Episode:  49 ,Return 98.0 , epsilon  0.67 , end= False\n",
      "Episode:  50 ,Return 69.0 , epsilon  0.67 , end= False\n",
      "Episode:  51 ,Return 42.0 , epsilon  0.66 , end= False\n",
      "Episode:  52 ,Return 40.0 , epsilon  0.66 , end= False\n",
      "Episode:  53 ,Return 18.0 , epsilon  0.65 , end= False\n",
      "Episode:  54 ,Return 48.0 , epsilon  0.65 , end= False\n",
      "Episode:  55 ,Return 70.0 , epsilon  0.64 , end= False\n",
      "Episode:  56 ,Return 82.0 , epsilon  0.64 , end= False\n",
      "Episode:  57 ,Return 64.0 , epsilon  0.63 , end= False\n",
      "Episode:  58 ,Return 95.0 , epsilon  0.63 , end= False\n",
      "Episode:  59 ,Return 42.0 , epsilon  0.62 , end= False\n",
      "Episode:  60 ,Return 147.0 , epsilon  0.62 , end= False\n",
      "Episode:  61 ,Return 65.0 , epsilon  0.61 , end= False\n",
      "Episode:  62 ,Return 118.0 , epsilon  0.61 , end= False\n",
      "Episode:  63 ,Return 37.0 , epsilon  0.6 , end= False\n",
      "Episode:  64 ,Return 143.0 , epsilon  0.6 , end= False\n",
      "Episode:  65 ,Return 167.0 , epsilon  0.59 , end= False\n",
      "Episode:  66 ,Return 95.0 , epsilon  0.59 , end= False\n",
      "Episode:  67 ,Return 174.0 , epsilon  0.58 , end= False\n",
      "Episode:  68 ,Return 23.0 , epsilon  0.58 , end= False\n",
      "Episode:  69 ,Return 206.0 , epsilon  0.57 , end= False\n",
      "Episode:  70 ,Return 19.0 , epsilon  0.57 , end= False\n",
      "Episode:  71 ,Return 57.0 , epsilon  0.57 , end= False\n",
      "Episode:  72 ,Return 99.0 , epsilon  0.56 , end= False\n",
      "Episode:  73 ,Return 311.0 , epsilon  0.56 , end= False\n",
      "Episode:  74 ,Return 16.0 , epsilon  0.55 , end= False\n",
      "Episode:  75 ,Return 11.0 , epsilon  0.55 , end= False\n",
      "Episode:  76 ,Return 93.0 , epsilon  0.54 , end= False\n",
      "Episode:  77 ,Return 113.0 , epsilon  0.54 , end= False\n",
      "Episode:  78 ,Return 113.0 , epsilon  0.53 , end= False\n",
      "Episode:  79 ,Return 26.0 , epsilon  0.53 , end= False\n",
      "Episode:  80 ,Return 144.0 , epsilon  0.53 , end= False\n",
      "Episode:  81 ,Return 64.0 , epsilon  0.52 , end= False\n",
      "Episode:  82 ,Return 104.0 , epsilon  0.52 , end= False\n",
      "Episode:  83 ,Return 116.0 , epsilon  0.51 , end= False\n",
      "Episode:  84 ,Return 185.0 , epsilon  0.51 , end= False\n",
      "Episode:  85 ,Return 29.0 , epsilon  0.51 , end= False\n",
      "Episode:  86 ,Return 212.0 , epsilon  0.5 , end= False\n",
      "Episode:  87 ,Return 169.0 , epsilon  0.5 , end= False\n",
      "Episode:  88 ,Return 38.0 , epsilon  0.49 , end= False\n",
      "Episode:  89 ,Return 134.0 , epsilon  0.49 , end= False\n",
      "Episode:  90 ,Return 51.0 , epsilon  0.49 , end= False\n",
      "Episode:  91 ,Return 129.0 , epsilon  0.48 , end= False\n",
      "Episode:  92 ,Return 23.0 , epsilon  0.48 , end= False\n",
      "Episode:  93 ,Return 18.0 , epsilon  0.47 , end= False\n",
      "Episode:  94 ,Return 120.0 , epsilon  0.47 , end= False\n",
      "Episode:  95 ,Return 110.0 , epsilon  0.47 , end= False\n",
      "Episode:  96 ,Return 164.0 , epsilon  0.46 , end= False\n",
      "Episode:  97 ,Return 145.0 , epsilon  0.46 , end= False\n",
      "Episode:  98 ,Return 148.0 , epsilon  0.46 , end= False\n",
      "Episode:  99 ,Return 64.0 , epsilon  0.45 , end= False\n",
      "Episode:  100 ,Return 108.0 , epsilon  0.45 , end= False\n",
      "Episode:  101 ,Return 142.0 , epsilon  0.44 , end= False\n",
      "Episode:  102 ,Return 69.0 , epsilon  0.44 , end= False\n",
      "Episode:  103 ,Return 21.0 , epsilon  0.44 , end= False\n",
      "Episode:  104 ,Return 132.0 , epsilon  0.43 , end= False\n",
      "Episode:  105 ,Return 200.0 , epsilon  0.43 , end= False\n",
      "Episode:  106 ,Return 163.0 , epsilon  0.43 , end= False\n",
      "Episode:  107 ,Return 183.0 , epsilon  0.42 , end= False\n",
      "Episode:  108 ,Return 247.0 , epsilon  0.42 , end= False\n",
      "Episode:  109 ,Return 167.0 , epsilon  0.42 , end= False\n",
      "Episode:  110 ,Return 382.0 , epsilon  0.41 , end= False\n",
      "Episode:  111 ,Return 157.0 , epsilon  0.41 , end= False\n",
      "Episode:  112 ,Return 71.0 , epsilon  0.41 , end= False\n",
      "Episode:  113 ,Return 39.0 , epsilon  0.4 , end= False\n",
      "Episode:  114 ,Return 142.0 , epsilon  0.4 , end= False\n",
      "Episode:  115 ,Return 145.0 , epsilon  0.4 , end= False\n",
      "Episode:  116 ,Return 110.0 , epsilon  0.39 , end= False\n",
      "Episode:  117 ,Return 142.0 , epsilon  0.39 , end= False\n",
      "Episode:  118 ,Return 140.0 , epsilon  0.39 , end= False\n",
      "Episode:  119 ,Return 147.0 , epsilon  0.38 , end= False\n",
      "Episode:  120 ,Return 14.0 , epsilon  0.38 , end= False\n",
      "Episode:  121 ,Return 144.0 , epsilon  0.38 , end= False\n",
      "Episode:  122 ,Return 156.0 , epsilon  0.38 , end= False\n",
      "Episode:  123 ,Return 133.0 , epsilon  0.37 , end= False\n",
      "Episode:  124 ,Return 28.0 , epsilon  0.37 , end= False\n",
      "Episode:  125 ,Return 290.0 , epsilon  0.37 , end= False\n",
      "Episode:  126 ,Return 76.0 , epsilon  0.36 , end= False\n",
      "Episode:  127 ,Return 142.0 , epsilon  0.36 , end= False\n",
      "Episode:  128 ,Return 13.0 , epsilon  0.36 , end= False\n",
      "Episode:  129 ,Return 92.0 , epsilon  0.35 , end= False\n",
      "Episode:  130 ,Return 76.0 , epsilon  0.35 , end= False\n",
      "Episode:  131 ,Return 167.0 , epsilon  0.35 , end= False\n",
      "Episode:  132 ,Return 301.0 , epsilon  0.35 , end= False\n",
      "Episode:  133 ,Return 23.0 , epsilon  0.34 , end= False\n",
      "Episode:  134 ,Return 127.0 , epsilon  0.34 , end= False\n",
      "Episode:  135 ,Return 159.0 , epsilon  0.34 , end= False\n",
      "Episode:  136 ,Return 70.0 , epsilon  0.34 , end= False\n",
      "Episode:  137 ,Return 143.0 , epsilon  0.33 , end= False\n",
      "Episode:  138 ,Return 142.0 , epsilon  0.33 , end= False\n",
      "Episode:  139 ,Return 177.0 , epsilon  0.33 , end= False\n",
      "Episode:  140 ,Return 39.0 , epsilon  0.32 , end= False\n",
      "Episode:  141 ,Return 174.0 , epsilon  0.32 , end= False\n",
      "Episode:  142 ,Return 181.0 , epsilon  0.32 , end= False\n",
      "Episode:  143 ,Return 167.0 , epsilon  0.32 , end= False\n",
      "Episode:  144 ,Return 216.0 , epsilon  0.31 , end= False\n",
      "Episode:  145 ,Return 58.0 , epsilon  0.31 , end= False\n",
      "Episode:  146 ,Return 108.0 , epsilon  0.31 , end= False\n",
      "Episode:  147 ,Return 184.0 , epsilon  0.31 , end= False\n",
      "Episode:  148 ,Return 111.0 , epsilon  0.3 , end= False\n",
      "Episode:  149 ,Return 144.0 , epsilon  0.3 , end= False\n",
      "Episode:  150 ,Return 163.0 , epsilon  0.3 , end= False\n",
      "Episode:  151 ,Return 248.0 , epsilon  0.3 , end= False\n",
      "Episode:  152 ,Return 270.0 , epsilon  0.29 , end= False\n",
      "Episode:  153 ,Return 264.0 , epsilon  0.29 , end= False\n",
      "Episode:  154 ,Return 168.0 , epsilon  0.29 , end= False\n",
      "Episode:  155 ,Return 167.0 , epsilon  0.29 , end= False\n",
      "Episode:  156 ,Return 190.0 , epsilon  0.29 , end= False\n",
      "Episode:  157 ,Return 111.0 , epsilon  0.28 , end= False\n",
      "Episode:  158 ,Return 126.0 , epsilon  0.28 , end= False\n",
      "Episode:  159 ,Return 124.0 , epsilon  0.28 , end= False\n",
      "Episode:  160 ,Return 127.0 , epsilon  0.28 , end= False\n",
      "Episode:  161 ,Return 114.0 , epsilon  0.27 , end= False\n",
      "Episode:  162 ,Return 68.0 , epsilon  0.27 , end= False\n",
      "Episode:  163 ,Return 108.0 , epsilon  0.27 , end= False\n",
      "Episode:  164 ,Return 163.0 , epsilon  0.27 , end= False\n",
      "Episode:  165 ,Return 194.0 , epsilon  0.27 , end= False\n",
      "Episode:  166 ,Return 224.0 , epsilon  0.26 , end= False\n",
      "Episode:  167 ,Return 183.0 , epsilon  0.26 , end= False\n",
      "Episode:  168 ,Return 164.0 , epsilon  0.26 , end= False\n",
      "Episode:  169 ,Return 87.0 , epsilon  0.26 , end= False\n",
      "Episode:  170 ,Return 132.0 , epsilon  0.26 , end= False\n",
      "Episode:  171 ,Return 125.0 , epsilon  0.25 , end= False\n",
      "Episode:  172 ,Return 148.0 , epsilon  0.25 , end= False\n",
      "Episode:  173 ,Return 228.0 , epsilon  0.25 , end= False\n",
      "Episode:  174 ,Return 164.0 , epsilon  0.25 , end= False\n",
      "Episode:  175 ,Return 133.0 , epsilon  0.25 , end= False\n",
      "Episode:  176 ,Return 237.0 , epsilon  0.24 , end= False\n",
      "Episode:  177 ,Return 244.0 , epsilon  0.24 , end= False\n",
      "Episode:  178 ,Return 247.0 , epsilon  0.24 , end= False\n",
      "Episode:  179 ,Return 199.0 , epsilon  0.24 , end= False\n",
      "Episode:  180 ,Return 169.0 , epsilon  0.24 , end= False\n",
      "Episode:  181 ,Return 170.0 , epsilon  0.23 , end= False\n",
      "Episode:  182 ,Return 191.0 , epsilon  0.23 , end= False\n",
      "Episode:  183 ,Return 202.0 , epsilon  0.23 , end= False\n",
      "Episode:  184 ,Return 149.0 , epsilon  0.23 , end= False\n",
      "Episode:  185 ,Return 177.0 , epsilon  0.23 , end= False\n",
      "Episode:  186 ,Return 147.0 , epsilon  0.22 , end= False\n",
      "Episode:  187 ,Return 12.0 , epsilon  0.22 , end= False\n",
      "Episode:  188 ,Return 191.0 , epsilon  0.22 , end= False\n",
      "Episode:  189 ,Return 203.0 , epsilon  0.22 , end= False\n",
      "Episode:  190 ,Return 171.0 , epsilon  0.22 , end= False\n",
      "Episode:  191 ,Return 158.0 , epsilon  0.22 , end= False\n",
      "Episode:  192 ,Return 163.0 , epsilon  0.21 , end= False\n",
      "Episode:  193 ,Return 186.0 , epsilon  0.21 , end= False\n",
      "Episode:  194 ,Return 246.0 , epsilon  0.21 , end= False\n",
      "Episode:  195 ,Return 188.0 , epsilon  0.21 , end= False\n",
      "Episode:  196 ,Return 158.0 , epsilon  0.21 , end= False\n",
      "Episode:  197 ,Return 125.0 , epsilon  0.21 , end= False\n",
      "Episode:  198 ,Return 149.0 , epsilon  0.2 , end= False\n",
      "Episode:  199 ,Return 206.0 , epsilon  0.2 , end= False\n",
      "Episode:  200 ,Return 345.0 , epsilon  0.2 , end= False\n",
      "Episode:  201 ,Return 500.0 , epsilon  0.2 , end= True\n",
      "Episode:  202 ,Return 500.0 , epsilon  0.2 , end= True\n",
      "Episode:  203 ,Return 203.0 , epsilon  0.2 , end= False\n",
      "Episode:  204 ,Return 500.0 , epsilon  0.19 , end= True\n",
      "Episode:  205 ,Return 500.0 , epsilon  0.19 , end= True\n",
      "Episode:  206 ,Return 500.0 , epsilon  0.19 , end= True\n",
      "Episode:  207 ,Return 500.0 , epsilon  0.19 , end= True\n",
      "Objectif atteint :)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_step = 0  # comptage du nombre total de mouvement\n",
    "histoReturn=[] # pour graphique sur historique récompense\n",
    "epsilon=epsilon_max\n",
    "checkpoint_path=\"cartpole-save.weights.h5\"\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "goal450=0\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    # somme de la récompense total pour une cycle\n",
    "    Return = 0\n",
    "    \n",
    "    # reset env et conversion state\n",
    "    state = trans_state(env.reset()[0])\n",
    "    done=False\n",
    "    truncated=False\n",
    "    while not(done or truncated):\n",
    "        \n",
    "        # décommenter pour affichage\n",
    "        # env.render()\n",
    "    \n",
    "        time_step += 1\n",
    "        \n",
    "        # copie des poids du réseau d'entrainement vers le réseau cible selon la fréquence choisie\n",
    "        if time_step % dqn.update_freq == 0:\n",
    "            dqn.update_weights()\n",
    "        \n",
    "        # sélection d'une action selon notre politique\n",
    "        action = dqn.policy(state,epsilon)\n",
    "        \n",
    "        # jouer l'action\n",
    "        next_state, reward, done, truncated , _ = env.step(action)\n",
    "        next_state=trans_state(next_state) # reformatage\n",
    "        if truncated:\n",
    "            done=True \n",
    "\n",
    "        # enregistrement pour replay\n",
    "        dqn.store_transition(state, action, reward, next_state, done)\n",
    "        \n",
    "        # et shift d'état\n",
    "        state = next_state\n",
    "        \n",
    "        # cumul du retour G\n",
    "        Return += reward\n",
    "\n",
    "        # Done ?\n",
    "        if done or truncated:\n",
    "            # affichage du résultat du cyle\n",
    "            print('Episode: ',i, ',' 'Return', Return,', epsilon ',np.round(epsilon,2),', end=',truncated)\n",
    "            # ou\n",
    "            # mise àa jour de notre graphique sur les gains tous les 10 cycles\n",
    "            #if i % 10 == 0:\n",
    "            #    ax.clear()\n",
    "            #    ax.plot(histoReturn)\n",
    "            #    display(fig)\n",
    "            #    clear_output(wait=True)\n",
    "    \n",
    "            # on décremmente epsilon\n",
    "            epsilon *= epsilon_decay\n",
    "            epsilon = max(epsilon_min, epsilon)\n",
    "            histoReturn.append(Return)\n",
    "            # Sauvegarde des poids tous les 50 cycles\n",
    "            if i % 50 == 0:\n",
    "                dqn.main_network.save_weights(checkpoint_path)\n",
    "            break\n",
    "\n",
    "        # à partir de + batch-size on entraine le reseau\n",
    "        if len(dqn.replay_buffer) > batch_size:\n",
    "            dqn.train_model(batch_size)\n",
    "\n",
    "    if Return > 450 :\n",
    "        goal450 += 1\n",
    "        if goal450==4:\n",
    "            print(\"Objectif atteint :)\")\n",
    "            break\n",
    "    else:\n",
    "        goal450=0            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5613f7f-689b-4932-880e-c6f65d7eeccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6400190f-d14b-4eca-8d05-303063e47c2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Visualisons le résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4a14087-f533-41a3-9d02-cbd0cd265952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.wrappers import RecordEpisodeStatistics, RecordVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aec39232-d9d4-41ff-9e94-7bd7d42624bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = 'CartPole-v1'\n",
    "\n",
    "env_test = gym.make(ENV_NAME,render_mode=\"rgb_array\")\n",
    "env_test = RecordVideo(env, video_folder=\"video\", name_prefix=\"eval\",\n",
    "                  episode_trigger=lambda x: True)\n",
    "nb_actions = env_test.action_space.n # Nombre d'action\n",
    "nb_obs = env_test.observation_space.shape[0] # nombre de paramètre pour décrire l'environnement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a123316b-b843-4fda-be72-d12b468e090c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7367a47-86fa-4746-9f5a-ad57e9bad9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupiter2/data/venv/rl/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# optionnel  si vous démarrer sans exécuter les cellules prédédentes\n",
    "dqn = DQN(env_test.observation_space.shape[0],env_test.action_space.n,0.0,0.0)\n",
    "dqn.main_network.load_weights(\"cartpole-save.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "213f405d-4599-4834-b7f6-54a3d4773c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gain 128.0\n"
     ]
    }
   ],
   "source": [
    "state=trans_state(env_test.reset()[0])\n",
    "done = False\n",
    "truncated=False\n",
    "Gain=0\n",
    "while not (done or truncated):\n",
    "    action = dqn.policy(state,0)\n",
    "    next_state, reward, done, truncated , _ = env_test.step(action)\n",
    "    Gain += reward\n",
    "    state=trans_state(next_state)\n",
    "print(f\"Gain {Gain}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55367f5a-aecc-4b9b-bc9c-0615722c3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18daef13-6824-4101-ab60-fbe38e4dafbf",
   "metadata": {},
   "source": [
    "------\n",
    "Labo\n",
    "\n",
    "Décomposons notre entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bca348-5d75-447b-af6f-3c2688285878",
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch = random.sample(dqn.replay_buffer,batch_size)\n",
    "states, actions, rewards, next_states, dones = map(np.array, zip(*minibatch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc7e49-a746-474e-abc8-5ffa9e551f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "states=states.squeeze()\n",
    "next_states=next_states.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66022ba4-1c20-4bed-9978-98e7ec2e2d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311a9a96-5df7-4f47-b714-a7ba99155504",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_values = dqn.main_network.predict(states,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40cc57d-e678-4d07-8607-32d6f45d6471",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3d702-3e67-48b1-bc2e-ca5b0956d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0681927d-ce42-4e23-b070-7200cf981430",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.target_network.predict(next_states,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc088827-f7c4-4c63-b195-06fca13b5a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3139d2f-e4ff-4f85-b34e-a4048446c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amax(dqn.target_network.predict(next_states,verbose=0),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f9c983-3477-4d3a-803f-a23ca0878378",
   "metadata": {},
   "outputs": [],
   "source": [
    "Updates = rewards + dqn.gamma * np.amax(dqn.target_network.predict(next_states,verbose=0),axis=1) * (1-dones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41009d7d-b254-471e-ad4d-a67ae056049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf21546-3582-422e-aa6f-50dda9e2500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a1a6b7-3aec-40d3-929a-088787a9009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_values_C =Q_values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513e40d-b126-4748-a744-759ecc753e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_values_C[ np.arange(10),actions] = Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d48cb5-0584-49c9-8e19-d84800814bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_values_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47535d91-a710-4858-ae6d-6ad9c4a43901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
